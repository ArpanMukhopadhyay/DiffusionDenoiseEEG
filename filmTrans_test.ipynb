{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a75fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import preprocessing\n",
    "from diffusers import UNet1DModel, DDPMScheduler, DDIMScheduler\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b15ea7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rms(records, multi_channels):\n",
    "    if multi_channels == 1:\n",
    "        n = records.shape[0]\n",
    "        rms = 0\n",
    "        for i in range(n):\n",
    "            rms_t = np.sum([records[i]**2]/len(records[i]))\n",
    "            rms += rms_t\n",
    "        return rms/n\n",
    "    \n",
    "    if multi_channels == 0:\n",
    "        rms = np.sum([records**2])/ len(records)\n",
    "        return rms\n",
    "\n",
    "\n",
    "def snr(signal, noisy):\n",
    "    snr = 10 * np.log10(signal/noisy)\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d714c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_signal(signal, comb):\n",
    "    res = []\n",
    "\n",
    "    for i in range(comb):\n",
    "        rand_num = np.random.permutation(signal.shape[0])\n",
    "        shuffled_dataset = signal[rand_num, :]\n",
    "        shuffled_dataset = shuffled_dataset.reshape(signal.shape[0], signal.shape[1])\n",
    "        res.append(shuffled_dataset)\n",
    "    \n",
    "    random_result = np.array(res)\n",
    "\n",
    "    return random_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6db2fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(comb):\n",
    "    eeg_data = np.load('./data/EEG_all_epochs.npy')\n",
    "    noise_data = np.load('./data/EMG_all_epochs.npy')\n",
    "\n",
    "    eeg_random = np.squeeze(random_signal(signal=eeg_data, comb=1))\n",
    "    noise_random = np.squeeze(random_signal(signal=noise_data, comb=1))\n",
    "\n",
    "    reuse_num = noise_random.shape[0] - eeg_random.shape[0]\n",
    "    eeg_reuse = eeg_random[0: reuse_num, :]\n",
    "    eeg_random = np.vstack([eeg_reuse, eeg_random])\n",
    "    print(f'EEG shape after crop and resuse to match EMG samples: {eeg_random.shape[0]}')\n",
    "\n",
    "    t = noise_random.shape[1]\n",
    "    train_num = round(eeg_random.shape[0] * 0.9)\n",
    "    test_num = round(eeg_random.shape[0] - train_num)\n",
    "\n",
    "    train_eeg = eeg_random[0: train_num, :]\n",
    "    test_eeg = eeg_random[train_num: train_num + test_num,:]\n",
    "\n",
    "    train_noise = noise_random[0: train_num, :]\n",
    "    test_noise = noise_random[train_num: train_num+test_num, :]\n",
    "\n",
    "    EEG_train = random_signal(signal=train_eeg, comb=comb).reshape(comb * train_eeg.shape[0],t)\n",
    "    NOISE_train = random_signal(signal=train_noise, comb=comb).reshape(comb * train_noise.shape[0], t)\n",
    "\n",
    "    EEG_test = random_signal(signal=test_eeg, comb=comb).reshape(comb * test_eeg.shape[0],t)\n",
    "    NOISE_test = random_signal(signal=test_noise, comb=comb).reshape(comb * test_noise.shape[0], t)\n",
    "\n",
    "    print(f\"train data clean shape: {EEG_train.shape}\")\n",
    "    print(f\"train data noise shape: {NOISE_train.shape}\")\n",
    "\n",
    "    sn_train = []\n",
    "    eeg_train = []\n",
    "    all_sn_test = []\n",
    "    all_eeg_test = []\n",
    "\n",
    "    SNR_train_dB = np.random.uniform(-7.0, 3.0, (EEG_train.shape[0]))\n",
    "    print(SNR_train_dB.shape)\n",
    "    SNR_train = np.sqrt(10**(0.1*(SNR_train_dB)))\n",
    "\n",
    "\n",
    "    for i in range(EEG_train.shape[0]):\n",
    "        noise = preprocessing.scale(NOISE_train[i])\n",
    "        EEG = preprocessing.scale(EEG_train[i])\n",
    "\n",
    "        alpha = get_rms(EEG, 0) / (get_rms(noise, 0 ) * SNR_train[i])\n",
    "        noise *= alpha\n",
    "        signal_noise = EEG + noise\n",
    "\n",
    "        sn_train.append(signal_noise)\n",
    "        eeg_train.append(EEG)\n",
    "    \n",
    "    SNR_test_dB = np.linspace(-7.0, 3.0, num=(11))\n",
    "    SNR_test = np.sqrt(10 ** (0.1 * SNR_test_dB))\n",
    "\n",
    "    for i in range(11):\n",
    "        sn_test = []\n",
    "        eeg_test = []\n",
    "        for k in range(EEG_test.shape[0]):\n",
    "            noise = preprocessing.scale(NOISE_test[k])\n",
    "            EEG = preprocessing.scale(EEG_test[k])\n",
    "\n",
    "            alpha = get_rms(EEG,0) / (get_rms(noise, 0) * SNR_test[i])\n",
    "            noise *= alpha\n",
    "            signal_noise = EEG + noise\n",
    "\n",
    "            sn_test.append(signal_noise)\n",
    "            eeg_test.append(EEG)\n",
    "        \n",
    "        sn_test = np.array(sn_test)\n",
    "        eeg_test = np.array(eeg_test)\n",
    "\n",
    "        all_sn_test.append(sn_test)\n",
    "        all_eeg_test.append(eeg_test)\n",
    "    \n",
    "    X_train = np.array(sn_train)\n",
    "    y_train = np.array(eeg_train)\n",
    "\n",
    "    X_test = np.array(all_sn_test)\n",
    "    y_test = np.array(all_eeg_test)\n",
    "\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "\n",
    "    X_test = np.expand_dims(X_test, axis=2)\n",
    "    y_test = np.expand_dims(y_test, axis=2)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "398aec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "df1cb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG shape after crop and resuse to match EMG samples: 5598\n",
      "train data clean shape: (55418, 512)\n",
      "train data noise shape: (55418, 512)\n",
      "(55418,)\n",
      "(55418, 1, 512) (55418, 1, 512)\n",
      "(11, 6160, 1, 512) (11, 6160, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_data(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "effcbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size = 0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "188c4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "455cf9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5542, 1, 512) (5542, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e968288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([49876, 1, 512])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([5542, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "X_val, y_val = torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
    "print(type(X_train), type(y_train))\n",
    "print(X_train.shape)\n",
    "print(type(X_val), type(y_val))\n",
    "print(X_val.shape)\n",
    "# X_train.to(device), y_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "24345873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEgDataSet(Dataset):\n",
    "    def __init__(self, X_noisy: torch.tensor, y_clean: torch.tensor):\n",
    "        self.xn = X_noisy.float()\n",
    "        self.yn = y_clean.float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.xn.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.xn[i], self.yn[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228d5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of UNet1DModel(\n",
       "  (time_proj): GaussianFourierProjection()\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock1D(\n",
       "      (down): Downsample1d()\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(2, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(2, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1-2): 2 x ResConvBlock(\n",
       "          (conv_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DownBlock1D(\n",
       "      (down): Downsample1d()\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1-2): 2 x ResConvBlock(\n",
       "          (conv_1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): DownBlock1D(\n",
       "      (down): Downsample1d()\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1-2): 2 x ResConvBlock(\n",
       "          (conv_1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock1D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(256, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1): ResConvBlock(\n",
       "          (conv_1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (2): ResConvBlock(\n",
       "          (conv_skip): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (up): Upsample1d()\n",
       "    )\n",
       "    (1): UpBlock1D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1): ResConvBlock(\n",
       "          (conv_1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (2): ResConvBlock(\n",
       "          (conv_skip): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (up): Upsample1d()\n",
       "    )\n",
       "    (2): UpBlock1D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1): ResConvBlock(\n",
       "          (conv_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (2): ResConvBlock(\n",
       "          (conv_skip): Conv1d(32, 1, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(32, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (up): Upsample1d()\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock1D(\n",
       "    (down): Downsample1d()\n",
       "    (up): Upsample1d()\n",
       "    (attentions): ModuleList(\n",
       "      (0-5): 6 x SelfAttention1d(\n",
       "        (group_norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (proj_attn): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-5): 6 x ResConvBlock(\n",
       "        (conv_1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (gelu_1): GELU(approximate='none')\n",
       "        (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (gelu_2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet1DModel(\n",
    "    sample_size=512,\n",
    "    in_channels=2,\n",
    "    out_channels=1,\n",
    "    layers_per_block=3,\n",
    "    block_out_channels=(64,128,256),\n",
    "    down_block_types=(\n",
    "        \"DownBlock1D\",\n",
    "        \"DownBlock1D\",\n",
    "        \"DownBlock1D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock1D\",\n",
    "        \"UpBlock1D\",\n",
    "        \"UpBlock1D\",\n",
    "    ),\n",
    ")\n",
    "model.to(device)\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "44e3e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiscale_cond(x):\n",
    "    c2 = F.interpolate(F.avg_pool1d(x,2,2,ceil_mode=True), size=x.shape[-1], mode=\"linear\", align_corners=False)\n",
    "    c4 = F.interpolate(F.avg_pool1d(x,4,4,ceil_mode=True), size=x.shape[-1], mode=\"linear\", align_corners=False)\n",
    "    return torch.cat([x, c2, c4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "38fc98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conditioner(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, hidden=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, hidden, kernel_size=7, padding=3, bias=False),\n",
    "            nn.GroupNorm(8, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(hidden, hidden, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(8, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(hidden, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "cond_net = Conditioner().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5297e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=400,\n",
    "    beta_schedule=\"linear\"\n",
    ")\n",
    "\n",
    "# scheduler = DDPMScheduler(\n",
    "#     num_train_timesteps=1000,\n",
    "#     beta_schedule=\"linear\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7375166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import amp\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import copy\n",
    "\n",
    "def train(model, scheduler, X_train, y_train, X_val, y_val,\n",
    "           *, epochs=10, batch_size=512, lr=2e-4,\n",
    "           wd=1e-5, grad_clip=1.0, cond_net):\n",
    "    data = EEgDataSet(X_train, y_train)\n",
    "    val_data = EEgDataSet(X_val, y_val)\n",
    "\n",
    "    dl = DataLoader(data, \n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    pin_memory=True)\n",
    "    \n",
    "    val_dl = DataLoader(val_data, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                drop_last=True,\n",
    "                pin_memory=True)\n",
    "    \n",
    "    optim = torch.optim.AdamW(list(model.parameters()) + list(cond_net.parameters()), lr=lr, weight_decay=wd)\n",
    "    scalar = amp.GradScaler(device=device)\n",
    "    import copy\n",
    "    ema_decay = 0.999\n",
    "    ema_model = copy.deepcopy(model).to(device).eval()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def ema_update():\n",
    "        for p, q in zip(model.parameters(), ema_model.parameters()):\n",
    "            q.data.mul_(ema_decay).add_(p.data, alpha=1 - ema_decay)\n",
    "\n",
    "    warmup_epochs = 5\n",
    "    lr_sched = CosineAnnealingLR(optim, T_max=epochs-warmup_epochs, eta_min=1e-5)\n",
    "    model.train()\n",
    "    cond_net.train()\n",
    "\n",
    "    for e in range(1, epochs + 1):\n",
    "\n",
    "        if e <= warmup_epochs:\n",
    "            warm_lr = lr * e/warmup_epochs\n",
    "            for pg in optim.param_groups:\n",
    "                pg[\"lr\"] = warm_lr\n",
    "\n",
    "        total = 0.0\n",
    "        n = 0\n",
    "        val_total = 0.0\n",
    "        val_n = 0\n",
    "\n",
    "        for x_noisy, x_clean in dl:\n",
    "            x_noisy = x_noisy.to(device, non_blocking=True).float()\n",
    "            x_clean = x_clean.to(device, non_blocking=True).float()\n",
    "\n",
    "            B = x_clean.size(0)\n",
    "            t = torch.randint(0, scheduler.config.num_train_timesteps, (B, ), device=device).long()\n",
    "            noise = torch.randn_like(x_clean)\n",
    "            x_t = scheduler.add_noise(x_clean, noise,t)\n",
    "            cond = cond_net(multiscale_cond(x_noisy))\n",
    "            x_in = torch.cat([x_t, cond], dim=1)\n",
    "            with amp.autocast(device_type=device, dtype=torch.float16):\n",
    "                pred_noise = model(x_in, t).sample\n",
    "                loss = F.mse_loss(pred_noise, noise)\n",
    "\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            scalar.scale(loss).backward()\n",
    "            if grad_clip:\n",
    "                scalar.unscale_(optim)\n",
    "                torch.nn.utils.clip_grad_norm_(list(model.parameters()) + list(cond_net.parameters()), grad_clip)\n",
    "            scalar.step(optim)\n",
    "            scalar.update()\n",
    "            ema_update()\n",
    "\n",
    "            total += loss.item() * B\n",
    "\n",
    "            n += B\n",
    "        \n",
    "        if e > warmup_epochs:\n",
    "            lr_sched.step()\n",
    "        model.eval()\n",
    "        cond_net.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_noisy, x_clean in val_dl:\n",
    "                x_noisy = x_noisy.to(device).float()\n",
    "                x_clean = x_clean.to(device).float()\n",
    "\n",
    "                B= x_clean.size(0)\n",
    "                t = torch.randint(0, scheduler.config.num_train_timesteps, (B,), device=device).long()\n",
    "                noise = torch.randn_like(x_clean)\n",
    "                x_t = scheduler.add_noise(x_clean, noise, t)\n",
    "                cond = cond_net(multiscale_cond(x_noisy))\n",
    "                with amp.autocast(device_type=device, dtype=torch.float16):\n",
    "                    pred_noise = ema_model(torch.cat([x_t, cond], dim=1), t).sample\n",
    "                    loss = F.mse_loss(pred_noise, noise)\n",
    "                val_total += loss.item() * B\n",
    "                val_n += B\n",
    "        val_loss = val_total / val_n\n",
    "        model.train()\n",
    "        cond_net.train()\n",
    "        print(f\"epoch {e}: train loss = {total/n: .4f}, val_los = {val_loss:.4f}\")\n",
    "    \n",
    "    return ema_model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4bba2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def denoise(model, scheduler, x_noisy, *, strength=0.25, num_inference_steps=50, cond_net):\n",
    "    model.eval()\n",
    "    cond_net.eval()\n",
    "    x = x_noisy.float().to(device)\n",
    "\n",
    "    scheduler.set_timesteps(num_inference_steps)\n",
    "    t_start = int(max(1, min(num_inference_steps-1, round(strength * num_inference_steps))))\n",
    "    timesteps = scheduler.timesteps[t_start:]\n",
    "    start_t = scheduler.timesteps[t_start]\n",
    "\n",
    "    outs = []\n",
    "    for i in range(0, x.size(0), 128):\n",
    "        X_noisy = x[i:i+128]\n",
    "        noise = torch.randn_like(X_noisy)\n",
    "        x_t = scheduler.add_noise(X_noisy, noise, start_t)\n",
    "        c = cond_net(multiscale_cond(X_noisy))\n",
    "        for t in timesteps:\n",
    "            x_in = torch.cat([x_t, c], dim=1)\n",
    "            eps = model(x_in, t).sample\n",
    "            x_t = scheduler.step(eps, t, x_t).prev_sample\n",
    "        \n",
    "        outs.append(x_t.detach().cpu())\n",
    "    return torch.cat(outs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6923f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrmse_time(yhat, y):\n",
    "    num = torch.mean((yhat- y)**2, dim=-1).sqrt()\n",
    "    den = torch.mean(y**2, dim=-1).sqrt() + 1e-8\n",
    "    return (num/den).mean().item()\n",
    "\n",
    "def cc (yhat, y):\n",
    "    yhat = yhat - yhat.mean(dim=-1, keepdim=True)\n",
    "    y = y - y.mean(dim=-1, keepdim=True)\n",
    "    num = (yhat*y).sum(dim=-1)\n",
    "    den = (yhat.norm(dim=-1)*y.norm(dim=-1) + 1e-8)\n",
    "\n",
    "    return (num/den).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "040a8ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train loss =  0.8233, val_los = 1.7311\n",
      "epoch 2: train loss =  0.6703, val_los = 1.3009\n",
      "epoch 3: train loss =  0.6656, val_los = 1.0726\n",
      "epoch 4: train loss =  0.6587, val_los = 0.9241\n",
      "epoch 5: train loss =  0.6562, val_los = 0.8302\n",
      "epoch 6: train loss =  0.6517, val_los = 0.7768\n",
      "epoch 7: train loss =  0.6501, val_los = 0.7517\n",
      "epoch 8: train loss =  0.6478, val_los = 0.7255\n",
      "epoch 9: train loss =  0.6461, val_los = 0.7142\n",
      "epoch 10: train loss =  0.6455, val_los = 0.7045\n",
      "epoch 11: train loss =  0.6452, val_los = 0.6980\n",
      "epoch 12: train loss =  0.6442, val_los = 0.6948\n",
      "epoch 13: train loss =  0.6428, val_los = 0.6866\n",
      "epoch 14: train loss =  0.6426, val_los = 0.6817\n",
      "epoch 15: train loss =  0.6418, val_los = 0.6820\n",
      "epoch 16: train loss =  0.6417, val_los = 0.6710\n",
      "epoch 17: train loss =  0.6409, val_los = 0.6732\n",
      "epoch 18: train loss =  0.6412, val_los = 0.6672\n",
      "epoch 19: train loss =  0.6405, val_los = 0.6642\n",
      "epoch 20: train loss =  0.6405, val_los = 0.6593\n",
      "epoch 21: train loss =  0.6384, val_los = 0.6558\n",
      "epoch 22: train loss =  0.6382, val_los = 0.6512\n",
      "epoch 23: train loss =  0.6374, val_los = 0.6504\n",
      "epoch 24: train loss =  0.6356, val_los = 0.6489\n",
      "epoch 25: train loss =  0.6364, val_los = 0.6459\n",
      "epoch 26: train loss =  0.6341, val_los = 0.6489\n",
      "epoch 27: train loss =  0.6342, val_los = 0.6451\n",
      "epoch 28: train loss =  0.6298, val_los = 0.6394\n",
      "epoch 29: train loss =  0.6290, val_los = 0.6413\n",
      "epoch 30: train loss =  0.6265, val_los = 0.6419\n",
      "epoch 31: train loss =  0.6235, val_los = 0.6384\n",
      "epoch 32: train loss =  0.6193, val_los = 0.6353\n",
      "epoch 33: train loss =  0.6184, val_los = 0.6376\n",
      "epoch 34: train loss =  0.6134, val_los = 0.6351\n",
      "epoch 35: train loss =  0.6116, val_los = 0.6385\n",
      "epoch 36: train loss =  0.6098, val_los = 0.6349\n",
      "epoch 37: train loss =  0.6067, val_los = 0.6338\n",
      "epoch 38: train loss =  0.6034, val_los = 0.6288\n",
      "epoch 39: train loss =  0.6023, val_los = 0.6306\n",
      "epoch 40: train loss =  0.6002, val_los = 0.6264\n",
      "epoch 41: train loss =  0.5987, val_los = 0.6235\n",
      "epoch 42: train loss =  0.5961, val_los = 0.6206\n",
      "epoch 43: train loss =  0.5947, val_los = 0.6168\n",
      "epoch 44: train loss =  0.5939, val_los = 0.6188\n",
      "epoch 45: train loss =  0.5901, val_los = 0.6170\n",
      "epoch 46: train loss =  0.5892, val_los = 0.6138\n",
      "epoch 47: train loss =  0.5881, val_los = 0.6081\n",
      "epoch 48: train loss =  0.5866, val_los = 0.6060\n",
      "epoch 49: train loss =  0.5855, val_los = 0.6027\n",
      "epoch 50: train loss =  0.5831, val_los = 0.6052\n",
      "epoch 51: train loss =  0.5827, val_los = 0.5997\n",
      "epoch 52: train loss =  0.5813, val_los = 0.5982\n",
      "epoch 53: train loss =  0.5807, val_los = 0.5961\n",
      "epoch 54: train loss =  0.5793, val_los = 0.5954\n",
      "epoch 55: train loss =  0.5785, val_los = 0.5907\n",
      "epoch 56: train loss =  0.5781, val_los = 0.5890\n",
      "epoch 57: train loss =  0.5766, val_los = 0.5869\n",
      "epoch 58: train loss =  0.5756, val_los = 0.5869\n",
      "epoch 59: train loss =  0.5740, val_los = 0.5808\n",
      "epoch 60: train loss =  0.5734, val_los = 0.5820\n",
      "epoch 61: train loss =  0.5726, val_los = 0.5818\n",
      "epoch 62: train loss =  0.5718, val_los = 0.5809\n",
      "epoch 63: train loss =  0.5709, val_los = 0.5801\n",
      "epoch 64: train loss =  0.5699, val_los = 0.5764\n",
      "epoch 65: train loss =  0.5696, val_los = 0.5780\n",
      "epoch 66: train loss =  0.5693, val_los = 0.5778\n",
      "epoch 67: train loss =  0.5684, val_los = 0.5760\n",
      "epoch 68: train loss =  0.5667, val_los = 0.5738\n",
      "epoch 69: train loss =  0.5660, val_los = 0.5727\n",
      "epoch 70: train loss =  0.5661, val_los = 0.5741\n",
      "epoch 71: train loss =  0.5656, val_los = 0.5693\n",
      "epoch 72: train loss =  0.5639, val_los = 0.5685\n",
      "epoch 73: train loss =  0.5642, val_los = 0.5676\n",
      "epoch 74: train loss =  0.5626, val_los = 0.5684\n",
      "epoch 75: train loss =  0.5635, val_los = 0.5695\n",
      "epoch 76: train loss =  0.5627, val_los = 0.5679\n",
      "epoch 77: train loss =  0.5615, val_los = 0.5673\n",
      "epoch 78: train loss =  0.5618, val_los = 0.5662\n",
      "epoch 79: train loss =  0.5601, val_los = 0.5650\n",
      "epoch 80: train loss =  0.5608, val_los = 0.5620\n",
      "epoch 81: train loss =  0.5597, val_los = 0.5664\n",
      "epoch 82: train loss =  0.5591, val_los = 0.5639\n",
      "epoch 83: train loss =  0.5590, val_los = 0.5637\n",
      "epoch 84: train loss =  0.5596, val_los = 0.5614\n",
      "epoch 85: train loss =  0.5584, val_los = 0.5623\n",
      "epoch 86: train loss =  0.5582, val_los = 0.5642\n",
      "epoch 87: train loss =  0.5575, val_los = 0.5642\n",
      "epoch 88: train loss =  0.5577, val_los = 0.5628\n",
      "epoch 89: train loss =  0.5570, val_los = 0.5609\n",
      "epoch 90: train loss =  0.5572, val_los = 0.5608\n",
      "epoch 91: train loss =  0.5565, val_los = 0.5617\n",
      "epoch 92: train loss =  0.5562, val_los = 0.5605\n",
      "epoch 93: train loss =  0.5568, val_los = 0.5583\n",
      "epoch 94: train loss =  0.5561, val_los = 0.5594\n",
      "epoch 95: train loss =  0.5559, val_los = 0.5593\n",
      "epoch 96: train loss =  0.5567, val_los = 0.5599\n",
      "epoch 97: train loss =  0.5555, val_los = 0.5575\n",
      "epoch 98: train loss =  0.5554, val_los = 0.5589\n",
      "epoch 99: train loss =  0.5560, val_los = 0.5607\n",
      "epoch 100: train loss =  0.5557, val_los = 0.5572\n"
     ]
    }
   ],
   "source": [
    "ema_model = train(model, scheduler, X_train, y_train, X_val, y_val, epochs=100, batch_size=512, lr=1e-3, wd=0, cond_net=cond_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ee73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "df9f8dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6160, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "X_test_t = torch.from_numpy(X_test).to(device)\n",
    "y_test_t = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "print(X_test_t[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fab41710",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_scheduler = DDIMScheduler.from_config(scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1664d9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for SNR: -7\n",
      "RRMSE_t=0.9415, CC=0.4687\n",
      "Testing for SNR: -5\n",
      "RRMSE_t=0.8828, CC=0.5309\n",
      "Testing for SNR: -2\n",
      "RRMSE_t=0.7959, CC=0.6199\n",
      "Testing for SNR: -1\n",
      "RRMSE_t=0.7688, CC=0.6469\n",
      "Testing for SNR: 1\n",
      "RRMSE_t=0.7203, CC=0.6941\n",
      "Testing for SNR: 3\n",
      "RRMSE_t=0.6810, CC=0.7315\n"
     ]
    }
   ],
   "source": [
    "for s in [0, 2, 5, 6, 8, 10]:\n",
    "    print(f\"Testing for SNR: {-7+s}\")\n",
    "    y_ref = y_test_t[s].to(device)\n",
    "    y_hat = denoise(ema_model, inference_scheduler, X_test_t[s], strength=0.6, num_inference_steps=150, cond_net=cond_net)\n",
    "    y_hat = y_hat.to(device)\n",
    "    m = rrmse_time(y_hat, y_ref)\n",
    "    c = cc(y_hat, y_ref)\n",
    "    print(f\"RRMSE_t={m:.4f}, CC={c:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ad043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf297088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a1nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
