{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a75fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arpydarpy/miniconda3/envs/a1nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import preprocessing\n",
    "from diffusers import UNet1DModel, DDPMScheduler, DDIMScheduler\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15ea7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rms(records, multi_channels):\n",
    "    if multi_channels == 1:\n",
    "        n = records.shape[0]\n",
    "        rms = 0\n",
    "        for i in range(n):\n",
    "            rms_t = np.sum([records[i]**2]/len(records[i]))\n",
    "            rms += rms_t\n",
    "        return rms/n\n",
    "    \n",
    "    if multi_channels == 0:\n",
    "        rms = np.sum([records**2])/ len(records)\n",
    "        return rms\n",
    "\n",
    "def snr(signal, noisy):\n",
    "    snr = 10 * np.log10(signal/noisy)\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d714c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_signal(signal, comb):\n",
    "    res = []\n",
    "\n",
    "    for i in range(comb):\n",
    "        rand_num = np.random.permutation(signal.shape[0])\n",
    "        shuffled_dataset = signal[rand_num, :]\n",
    "        shuffled_dataset = shuffled_dataset.reshape(signal.shape[0], signal.shape[1])\n",
    "        res.append(shuffled_dataset)\n",
    "    \n",
    "    random_result = np.array(res)\n",
    "\n",
    "    return random_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db2fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(comb):\n",
    "    eeg_data = np.load('./data/EEG_all_epochs.npy')\n",
    "    noise_data = np.load('./data/EMG_all_epochs.npy')\n",
    "\n",
    "    eeg_random = np.squeeze(random_signal(signal=eeg_data, comb=1))\n",
    "    noise_random = np.squeeze(random_signal(signal=noise_data, comb=1))\n",
    "\n",
    "    reuse_num = noise_random.shape[0] - eeg_random.shape[0]\n",
    "    eeg_reuse = eeg_random[0: reuse_num, :]\n",
    "    eeg_random = np.vstack([eeg_reuse, eeg_random])\n",
    "    print(f'EEG shape after crop and resuse to match EMG samples: {eeg_random.shape[0]}')\n",
    "\n",
    "    t = noise_random.shape[1]\n",
    "    train_num = round(eeg_random.shape[0] * 0.9)\n",
    "    test_num = round(eeg_random.shape[0] - train_num)\n",
    "\n",
    "    train_eeg = eeg_random[0: train_num, :]\n",
    "    test_eeg = eeg_random[train_num: train_num + test_num,:]\n",
    "\n",
    "    train_noise = noise_random[0: train_num, :]\n",
    "    test_noise = noise_random[train_num: train_num+test_num, :]\n",
    "\n",
    "    EEG_train = random_signal(signal=train_eeg, comb=comb).reshape(comb * train_eeg.shape[0],t)\n",
    "    NOISE_train = random_signal(signal=train_noise, comb=comb).reshape(comb * train_noise.shape[0], t)\n",
    "\n",
    "    EEG_test = random_signal(signal=test_eeg, comb=comb).reshape(comb * test_eeg.shape[0],t)\n",
    "    NOISE_test = random_signal(signal=test_noise, comb=comb).reshape(comb * test_noise.shape[0], t)\n",
    "\n",
    "    print(f\"train data clean shape: {EEG_train.shape}\")\n",
    "    print(f\"train data noise shape: {NOISE_train.shape}\")\n",
    "\n",
    "    sn_train = []\n",
    "    eeg_train = []\n",
    "    all_sn_test = []\n",
    "    all_eeg_test = []\n",
    "\n",
    "    SNR_train_dB = np.random.uniform(-7.0, 3.0, (EEG_train.shape[0]))\n",
    "    print(SNR_train_dB.shape)\n",
    "    SNR_train = np.sqrt(10**(0.1*(SNR_train_dB)))\n",
    "\n",
    "\n",
    "    for i in range(EEG_train.shape[0]):\n",
    "        noise = preprocessing.scale(NOISE_train[i])\n",
    "        EEG = preprocessing.scale(EEG_train[i])\n",
    "\n",
    "        alpha = get_rms(EEG, 0) / (get_rms(noise, 0 ) * SNR_train[i])\n",
    "        noise *= alpha\n",
    "        signal_noise = EEG + noise\n",
    "\n",
    "        sn_train.append(signal_noise)\n",
    "        eeg_train.append(EEG)\n",
    "    \n",
    "    SNR_test_dB = np.linspace(-7.0, 3.0, num=(11))\n",
    "    SNR_test = np.sqrt(10 ** (0.1 * SNR_test_dB))\n",
    "\n",
    "    for i in range(11):\n",
    "        sn_test = []\n",
    "        eeg_test = []\n",
    "        for k in range(EEG_test.shape[0]):\n",
    "            noise = preprocessing.scale(NOISE_test[k])\n",
    "            EEG = preprocessing.scale(EEG_test[k])\n",
    "\n",
    "            alpha = get_rms(EEG,0) / (get_rms(noise, 0) * SNR_test[i])\n",
    "            noise *= alpha\n",
    "            signal_noise = EEG + noise\n",
    "\n",
    "            sn_test.append(signal_noise)\n",
    "            eeg_test.append(EEG)\n",
    "        \n",
    "        sn_test = np.array(sn_test)\n",
    "        eeg_test = np.array(eeg_test)\n",
    "\n",
    "        all_sn_test.append(sn_test)\n",
    "        all_eeg_test.append(eeg_test)\n",
    "    \n",
    "    X_train = np.array(sn_train)\n",
    "    y_train = np.array(eeg_train)\n",
    "\n",
    "    X_test = np.array(all_sn_test)\n",
    "    y_test = np.array(all_eeg_test)\n",
    "\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "\n",
    "    X_test = np.expand_dims(X_test, axis=2)\n",
    "    y_test = np.expand_dims(y_test, axis=2)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398aec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1cb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG shape after crop and resuse to match EMG samples: 5598\n",
      "train data clean shape: (55418, 512)\n",
      "train data noise shape: (55418, 512)\n",
      "(55418,)\n",
      "(55418, 1, 512) (55418, 1, 512)\n",
      "(11, 6160, 1, 512) (11, 6160, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_data(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effcbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size = 0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188c4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "455cf9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5542, 1, 512) (5542, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e968288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([49876, 1, 512])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([5542, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "X_val, y_val = torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
    "print(type(X_train), type(y_train))\n",
    "print(X_train.shape)\n",
    "print(type(X_val), type(y_val))\n",
    "print(X_val.shape)\n",
    "# X_train.to(device), y_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24345873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEgDataSet(Dataset):\n",
    "    def __init__(self, X_noisy: torch.tensor, y_clean: torch.tensor):\n",
    "        self.xn = X_noisy.float()\n",
    "        self.yn = y_clean.float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.xn.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.xn[i], self.yn[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c228d5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of UNet1DModel(\n",
       "  (time_proj): GaussianFourierProjection()\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock1D(\n",
       "      (down): Downsample1d()\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(2, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(2, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1-2): 2 x ResConvBlock(\n",
       "          (conv_1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DownBlock1D(\n",
       "      (down): Downsample1d()\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1-2): 2 x ResConvBlock(\n",
       "          (conv_1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): AttnDownBlock1D(\n",
       "      (down): Downsample1d()\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x SelfAttention1d(\n",
       "          (group_norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_attn): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1-2): 2 x ResConvBlock(\n",
       "          (conv_1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlock1D(\n",
       "      (down): Downsample1d()\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1-2): 2 x ResConvBlock(\n",
       "          (conv_1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock1D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(1024, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1): ResConvBlock(\n",
       "          (conv_1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (2): ResConvBlock(\n",
       "          (conv_skip): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(512, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (up): Upsample1d()\n",
       "    )\n",
       "    (1): AttnUpBlock1D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x SelfAttention1d(\n",
       "          (group_norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_attn): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1-2): 2 x ResConvBlock(\n",
       "          (conv_1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (up): Upsample1d()\n",
       "    )\n",
       "    (2): UpBlock1D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(256, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1): ResConvBlock(\n",
       "          (conv_1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (2): ResConvBlock(\n",
       "          (conv_skip): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (up): Upsample1d()\n",
       "    )\n",
       "    (3): UpBlock1D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResConvBlock(\n",
       "          (conv_skip): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (1): ResConvBlock(\n",
       "          (conv_1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "        (2): ResConvBlock(\n",
       "          (conv_skip): Conv1d(64, 1, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (conv_1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (gelu_1): GELU(approximate='none')\n",
       "          (conv_2): Conv1d(64, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (group_norm_2): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
       "          (gelu_2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (up): Upsample1d()\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock1D(\n",
       "    (down): Downsample1d()\n",
       "    (up): Upsample1d()\n",
       "    (attentions): ModuleList(\n",
       "      (0-5): 6 x SelfAttention1d(\n",
       "        (group_norm): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_attn): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-5): 6 x ResConvBlock(\n",
       "        (conv_1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (group_norm_1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "        (gelu_1): GELU(approximate='none')\n",
       "        (conv_2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (group_norm_2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "        (gelu_2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet1DModel(\n",
    "    sample_size=512,\n",
    "    in_channels=2,\n",
    "    out_channels=1,\n",
    "    layers_per_block=3,\n",
    "    block_out_channels=(64,128,256,512),\n",
    "    down_block_types=(\n",
    "        \"DownBlock1D\",\n",
    "        \"DownBlock1D\",\n",
    "        \"AttnDownBlock1D\",\n",
    "        \"DownBlock1D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock1D\",\n",
    "        \"AttnUpBlock1D\",\n",
    "        \"UpBlock1D\",\n",
    "        \"UpBlock1D\",\n",
    "    ),\n",
    ")\n",
    "model.to(device)\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38fc98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Conditioner(nn.Module):\n",
    "#     def __init__(self, in_channels=1, out_channels=32, hidden=120):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.branch_3 = nn.Conv1d(in_channels, hidden//3, kernel_size=3, padding=1)\n",
    "#         self.branch_7 = nn.Conv1d(in_channels, hidden//3, kernel_size=7, padding=3)\n",
    "#         self.branch_15 = nn.Conv1d(in_channels, hidden//3, kernel_size=15, padding=7)\n",
    "        \n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.GroupNorm(8, hidden),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Conv1d(hidden, hidden, kernel_size=7, padding=3),\n",
    "#             nn.GroupNorm(8, hidden),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Conv1d(hidden, hidden, kernel_size=7, padding=3),\n",
    "#             nn.GroupNorm(8, hidden),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Conv1d(hidden, out_channels, 1)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x3 = self.branch_3(x)\n",
    "#         x7 = self.branch_7(x)\n",
    "#         x15 = self.branch_15(x)\n",
    "#         x = torch.cat([x3, x7, x15], dim=1)\n",
    "#         return self.net(x)\n",
    "\n",
    "class Conditioner(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, hidden=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, hidden, kernel_size=7, padding=3),\n",
    "            nn.GroupNorm(8, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(hidden, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "cond_net = Conditioner().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5297e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = DDPMScheduler(\n",
    "#     num_train_timesteps=1000,\n",
    "#     beta_schedule=\"squaredcos_cap_v2\",\n",
    "#     prediction_type=\"sample\"\n",
    "# )\n",
    "\n",
    "scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_schedule=\"linear\",\n",
    "    prediction_type=\"sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7375166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import amp\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "def train(model, scheduler, X_train, y_train, X_val, y_val,\n",
    "           *, epochs=10, batch_size=512, lr=2e-4,\n",
    "           wd=1e-5, grad_clip=1.0, cond_net):\n",
    "    data = EEgDataSet(X_train, y_train)\n",
    "    val_data = EEgDataSet(X_val, y_val)\n",
    "\n",
    "    dl = DataLoader(data, \n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    pin_memory=True)\n",
    "    \n",
    "    val_dl = DataLoader(val_data, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                drop_last=True,\n",
    "                pin_memory=True)\n",
    "    \n",
    "    optim = torch.optim.AdamW(list(model.parameters()) + list(cond_net.parameters()), lr=lr, weight_decay=wd)\n",
    "    scalar = amp.GradScaler(device=device)\n",
    "\n",
    "    warmup_epochs = 5\n",
    "    lr_sched = CosineAnnealingLR(optim, T_max=epochs-warmup_epochs, eta_min=1e-5)\n",
    "    model.train()\n",
    "\n",
    "    best_val = float('inf')\n",
    "    for e in range(1, epochs + 1):\n",
    "\n",
    "        if e <= warmup_epochs:\n",
    "            warm_lr = lr * e/warmup_epochs\n",
    "            for pg in optim.param_groups:\n",
    "                pg[\"lr\"] = warm_lr\n",
    "\n",
    "        total = 0.0\n",
    "        n = 0\n",
    "        val_total = 0.0\n",
    "        val_n = 0\n",
    "\n",
    "        for x_noisy, x_clean in dl:\n",
    "            x_noisy = x_noisy.to(device, non_blocking=True).float()\n",
    "            x_clean = x_clean.to(device, non_blocking=True).float()\n",
    "\n",
    "            B = x_clean.size(0)\n",
    "            t = torch.randint(0, scheduler.config.num_train_timesteps, (B, ), device=device).long()\n",
    "            noise = torch.randn_like(x_clean)\n",
    "            x_t = scheduler.add_noise(x_clean, noise,t)\n",
    "\n",
    "            x_in = torch.cat([x_t, cond_net(x_noisy)], dim=1)\n",
    "            with amp.autocast(device_type=device, dtype=torch.float16):\n",
    "                pred_noise = model(x_in, t).sample\n",
    "                if scheduler.config.prediction_type == \"sample\":\n",
    "                    loss = F.mse_loss(pred_noise, x_clean)\n",
    "                else:\n",
    "                    loss = F.mse_loss(pred_noise, noise)\n",
    "\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            scalar.scale(loss).backward()\n",
    "            if grad_clip:\n",
    "                scalar.unscale_(optim)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scalar.step(optim)\n",
    "            scalar.update()\n",
    "\n",
    "            total += loss.item() * B\n",
    "\n",
    "            n += B\n",
    "        \n",
    "        if e > warmup_epochs:\n",
    "            lr_sched.step()\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_noisy, x_clean in val_dl:\n",
    "                x_noisy = x_noisy.to(device).float()\n",
    "                x_clean = x_clean.to(device).float()\n",
    "\n",
    "                B= x_clean.size(0)\n",
    "                t = torch.randint(0, scheduler.config.num_train_timesteps, (B,), device=device).long()\n",
    "                noise = torch.randn_like(x_clean)\n",
    "                x_t = scheduler.add_noise(x_clean, noise, t)\n",
    "                cond = cond_net(x_noisy)\n",
    "                with amp.autocast(device_type=device, dtype=torch.float16):\n",
    "                    pred_noise = model(torch.cat([x_t, cond], dim=1), t).sample\n",
    "                    if scheduler.config.prediction_type == \"sample\":\n",
    "                        loss = F.mse_loss(pred_noise, x_clean)\n",
    "                    else:\n",
    "                        loss = F.mse_loss(pred_noise, noise)\n",
    "                val_total += loss.item() * B\n",
    "                val_n += B\n",
    "        val_loss = val_total / val_n\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            torch.save({\"model\":model.state_dict()}, 'best_mode.pth')\n",
    "        model.train()\n",
    "        cond_net.train()\n",
    "        print(f\"epoch {e}: train loss = {total/n: .4f}, val_los = {val_loss:.4f}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4bba2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def denoise(model, scheduler, x_noisy, *, num_inference_steps=50, cond_net):\n",
    "    model.eval()\n",
    "    cond_net.eval()\n",
    "    x_noisy = x_noisy.float().to(device)\n",
    "    \n",
    "    scheduler.set_timesteps(num_inference_steps)\n",
    "    \n",
    "    outs = []\n",
    "    for i in range(0, x_noisy.size(0), 128):\n",
    "        X_noisy_batch = x_noisy[i:i+128]\n",
    "        \n",
    "        x_t = torch.randn_like(X_noisy_batch)\n",
    "        \n",
    "        c = cond_net(X_noisy_batch)\n",
    "        \n",
    "        for t in scheduler.timesteps:\n",
    "            x_in = torch.cat([x_t, c], dim=1)\n",
    "            eps = model(x_in, t).sample\n",
    "            x_t = scheduler.step(eps, t, x_t).prev_sample\n",
    "        \n",
    "        outs.append(x_t.detach().cpu())\n",
    "    \n",
    "    return torch.cat(outs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6923f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrmse_time(yhat, y):\n",
    "    num = torch.mean((yhat- y)**2, dim=-1).sqrt()\n",
    "    den = torch.mean(y**2, dim=-1).sqrt() + 1e-8\n",
    "    return (num/den).mean().item()\n",
    "\n",
    "def rrmse_spectral(yhat, y):\n",
    "    yhat_fft = torch.fft.rfft(yhat, dim=-1)\n",
    "    y_fft = torch.fft.rfft(y, dim=-1)\n",
    "    \n",
    "    yhat_mag = torch.abs(yhat_fft)\n",
    "    y_mag = torch.abs(y_fft)\n",
    "    \n",
    "    num = torch.mean((yhat_mag - y_mag)**2, dim=-1).sqrt()\n",
    "    den = torch.mean(y_mag**2, dim=-1).sqrt() + 1e-8\n",
    "    \n",
    "    return (num / den).mean().item()\n",
    "\n",
    "def cc (yhat, y):\n",
    "    yhat = yhat - yhat.mean(dim=-1, keepdim=True)\n",
    "    y = y - y.mean(dim=-1, keepdim=True)\n",
    "    num = (yhat*y).sum(dim=-1)\n",
    "    den = (yhat.norm(dim=-1)*y.norm(dim=-1) + 1e-8)\n",
    "\n",
    "    return (num/den).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "040a8ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train loss =  0.4357, val_los = 0.2405\n",
      "epoch 2: train loss =  0.2425, val_los = 0.2244\n",
      "epoch 3: train loss =  0.2224, val_los = 0.2092\n",
      "epoch 4: train loss =  0.2102, val_los = 0.2039\n",
      "epoch 5: train loss =  0.2163, val_los = 0.2030\n",
      "epoch 6: train loss =  0.1975, val_los = 0.1910\n",
      "epoch 7: train loss =  0.1917, val_los = 0.1885\n",
      "epoch 8: train loss =  0.1847, val_los = 0.1833\n",
      "epoch 9: train loss =  0.1765, val_los = 0.1716\n",
      "epoch 10: train loss =  0.1682, val_los = 0.1635\n",
      "epoch 11: train loss =  0.1576, val_los = 0.1547\n",
      "epoch 12: train loss =  0.1460, val_los = 0.1452\n",
      "epoch 13: train loss =  0.1323, val_los = 0.1346\n",
      "epoch 14: train loss =  0.1186, val_los = 0.1217\n",
      "epoch 15: train loss =  0.1063, val_los = 0.1115\n",
      "epoch 16: train loss =  0.0941, val_los = 0.1016\n",
      "epoch 17: train loss =  0.0824, val_los = 0.0919\n",
      "epoch 18: train loss =  0.0710, val_los = 0.0827\n",
      "epoch 19: train loss =  0.0622, val_los = 0.0763\n",
      "epoch 20: train loss =  0.0546, val_los = 0.0713\n",
      "epoch 21: train loss =  0.0481, val_los = 0.0648\n",
      "epoch 22: train loss =  0.0429, val_los = 0.0617\n",
      "epoch 23: train loss =  0.0392, val_los = 0.0573\n",
      "epoch 24: train loss =  0.0354, val_los = 0.0565\n",
      "epoch 25: train loss =  0.0327, val_los = 0.0546\n",
      "epoch 26: train loss =  0.0304, val_los = 0.0516\n",
      "epoch 27: train loss =  0.0286, val_los = 0.0510\n",
      "epoch 28: train loss =  0.0271, val_los = 0.0508\n",
      "epoch 29: train loss =  0.0259, val_los = 0.0483\n",
      "epoch 30: train loss =  0.0248, val_los = 0.0491\n",
      "epoch 31: train loss =  0.0239, val_los = 0.0477\n",
      "epoch 32: train loss =  0.0231, val_los = 0.0467\n",
      "epoch 33: train loss =  0.0224, val_los = 0.0469\n",
      "epoch 34: train loss =  0.0218, val_los = 0.0468\n",
      "epoch 35: train loss =  0.0213, val_los = 0.0467\n",
      "epoch 36: train loss =  0.0209, val_los = 0.0462\n",
      "epoch 37: train loss =  0.0205, val_los = 0.0470\n",
      "epoch 38: train loss =  0.0201, val_los = 0.0457\n",
      "epoch 39: train loss =  0.0199, val_los = 0.0467\n",
      "epoch 40: train loss =  0.0196, val_los = 0.0465\n",
      "epoch 41: train loss =  0.0194, val_los = 0.0467\n",
      "epoch 42: train loss =  0.0192, val_los = 0.0461\n",
      "epoch 43: train loss =  0.0191, val_los = 0.0461\n",
      "epoch 44: train loss =  0.0189, val_los = 0.0472\n",
      "epoch 45: train loss =  0.0188, val_los = 0.0471\n",
      "epoch 46: train loss =  0.0187, val_los = 0.0472\n",
      "epoch 47: train loss =  0.0187, val_los = 0.0476\n",
      "epoch 48: train loss =  0.0186, val_los = 0.0469\n",
      "epoch 49: train loss =  0.0186, val_los = 0.0477\n",
      "epoch 50: train loss =  0.0185, val_los = 0.0468\n"
     ]
    }
   ],
   "source": [
    "train(model, scheduler, X_train, y_train, X_val, y_val, epochs=50, batch_size=512, lr=1e-3, wd=0, cond_net=cond_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df9f8dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6160, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "X_test_t = torch.from_numpy(X_test).to(device)\n",
    "y_test_t = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "print(X_test_t[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fab41710",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_scheduler = DDIMScheduler.from_config(scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1664d9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for SNR: -7\n",
      "RRMSE_t=0.5670, RRMSE_s=0.4225 CC=0.8165\n",
      "Testing for SNR: -5\n",
      "RRMSE_t=0.5326, RRMSE_s=0.4079 CC=0.8481\n",
      "Testing for SNR: -2\n",
      "RRMSE_t=0.5050, RRMSE_s=0.3954 CC=0.8717\n",
      "Testing for SNR: -1\n",
      "RRMSE_t=0.4996, RRMSE_s=0.3930 CC=0.8762\n",
      "Testing for SNR: 1\n",
      "RRMSE_t=0.4919, RRMSE_s=0.3896 CC=0.8826\n",
      "Testing for SNR: 3\n",
      "RRMSE_t=0.4869, RRMSE_s=0.3875 CC=0.8867\n"
     ]
    }
   ],
   "source": [
    "rm_t = []\n",
    "rm_s = []\n",
    "cc_list = []\n",
    "for s in [0, 2, 5, 6, 8, 10]:\n",
    "    print(f\"Testing for SNR: {-7+s}\")\n",
    "    y_ref = y_test_t[s].to(device)\n",
    "    y_hat = denoise(model, inference_scheduler, X_test_t[s], num_inference_steps=50, cond_net=cond_net)\n",
    "    y_hat = y_hat.to(device)\n",
    "    m = rrmse_time(y_hat, y_ref)\n",
    "    s = rrmse_spectral(y_hat, y_ref)\n",
    "    c = cc(y_hat, y_ref)\n",
    "    print(f\"RRMSE_t={m:.4f}, RRMSE_s={s:.4f} CC={c:.4f}\")\n",
    "    rm_t.append(m)\n",
    "    rm_s.append(s)\n",
    "    cc_list.append(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ad043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf297088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a1nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
